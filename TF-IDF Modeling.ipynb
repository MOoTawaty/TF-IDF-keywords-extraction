{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "09689eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machine learning ml is the study of computer algorithms that can improve automatically through experience and by the use of data', ' it is seen as a part of artificial intelligence', 'machine learning algorithms build a model based on sample data known as training data in order to make predictions or', 'decisions without being explicitly programmed to do so machine learning algorithms are used in a wide variety of applications', 'such as in medicine email filtering speech recognition and computer vision', 'where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks']\n"
     ]
    }
   ],
   "source": [
    "#Reading the data\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "\n",
    "def read_data(file):\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "data = read_data('data.txt')\n",
    "data = data.lower()\n",
    "data = data.translate(str.maketrans('', '', string.punctuation))\n",
    "lines = data.split('\\n')\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "37318e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop_words\n",
      " ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "#Stop Words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "addtional_words = ['used', 'use', 'wide', 'vision', 'variety', 'seen', 'speech', 'study', 'tasks', 'training','improve', 'needed']\n",
    "stop_words = stopwords.words('english')\n",
    "useless_words = stop_words + addtional_words\n",
    "print(\"stop_words\\n\", stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "56ed3640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names \n",
      " ['algorithms applications' 'algorithms automatically' 'algorithms build'\n",
      " 'algorithms perform' 'artificial intelligence' 'automatically experience'\n",
      " 'based sample' 'build model' 'computer algorithms'\n",
      " 'conventional algorithms' 'data known' 'data order' 'decisions without'\n",
      " 'develop conventional' 'difficult unfeasible' 'email filtering'\n",
      " 'experience data' 'explicitly programmed' 'filtering recognition'\n",
      " 'known data' 'learning algorithms' 'learning ml' 'machine learning'\n",
      " 'make predictions' 'medicine email' 'ml computer' 'model based'\n",
      " 'order make' 'part artificial' 'programmed machine'\n",
      " 'recognition computer' 'sample data' 'unfeasible develop'\n",
      " 'without explicitly']\n"
     ]
    }
   ],
   "source": [
    "#Cleaning & Modeling the data with TF-IDFVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words = useless_words, ngram_range=(2,2))\n",
    "matrix  = vectorizer.fit_transform(lines)\n",
    "print(\"Feature Names \\n\", vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "0c9712c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the Matrix \n",
      " (6, 34)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of the Matrix \\n\", matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e88062e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067811865476\n",
      "(1, 4)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import unravel_index\n",
    "\n",
    "data = matrix.toarray()\n",
    "max_value = np.max(data)\n",
    "max_value2 = data.argmax()\n",
    "max_value_index = unravel_index(data.argmax(), data.shape)\n",
    "print(max_value)\n",
    "print(max_value_index)\n",
    "print (data[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5269857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c542fbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithms build</th>\n",
       "      <th>algorithms improve</th>\n",
       "      <th>algorithms perform</th>\n",
       "      <th>algorithms used</th>\n",
       "      <th>artificial intelligence</th>\n",
       "      <th>automatically experience</th>\n",
       "      <th>based sample</th>\n",
       "      <th>build model</th>\n",
       "      <th>computer algorithms</th>\n",
       "      <th>computer vision</th>\n",
       "      <th>...</th>\n",
       "      <th>sample data</th>\n",
       "      <th>seen artificial</th>\n",
       "      <th>speech recognition</th>\n",
       "      <th>study computer</th>\n",
       "      <th>training data</th>\n",
       "      <th>unfeasible develop</th>\n",
       "      <th>use data</th>\n",
       "      <th>used wide</th>\n",
       "      <th>variety applications</th>\n",
       "      <th>wide variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.286867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286867</td>\n",
       "      <td>0.286867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350248</td>\n",
       "      <td>0.350248</td>\n",
       "      <td>0.350248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   algorithms build  algorithms improve  algorithms perform  algorithms used  \\\n",
       "0          0.000000            0.324797            0.000000         0.000000   \n",
       "1          0.000000            0.000000            0.000000         0.000000   \n",
       "2          0.286867            0.000000            0.000000         0.000000   \n",
       "3          0.000000            0.000000            0.000000         0.350248   \n",
       "4          0.000000            0.000000            0.000000         0.000000   \n",
       "5          0.000000            0.000000            0.377964         0.000000   \n",
       "\n",
       "   artificial intelligence  automatically experience  based sample  \\\n",
       "0                 0.000000                  0.324797      0.000000   \n",
       "1                 0.707107                  0.000000      0.000000   \n",
       "2                 0.000000                  0.000000      0.286867   \n",
       "3                 0.000000                  0.000000      0.000000   \n",
       "4                 0.000000                  0.000000      0.000000   \n",
       "5                 0.000000                  0.000000      0.000000   \n",
       "\n",
       "   build model  computer algorithms  computer vision  ...  sample data  \\\n",
       "0     0.000000             0.324797         0.000000  ...     0.000000   \n",
       "1     0.000000             0.000000         0.000000  ...     0.000000   \n",
       "2     0.286867             0.000000         0.000000  ...     0.286867   \n",
       "3     0.000000             0.000000         0.000000  ...     0.000000   \n",
       "4     0.000000             0.000000         0.408248  ...     0.000000   \n",
       "5     0.000000             0.000000         0.000000  ...     0.000000   \n",
       "\n",
       "   seen artificial  speech recognition  study computer  training data  \\\n",
       "0         0.000000            0.000000        0.324797       0.000000   \n",
       "1         0.707107            0.000000        0.000000       0.000000   \n",
       "2         0.000000            0.000000        0.000000       0.286867   \n",
       "3         0.000000            0.000000        0.000000       0.000000   \n",
       "4         0.000000            0.408248        0.000000       0.000000   \n",
       "5         0.000000            0.000000        0.000000       0.000000   \n",
       "\n",
       "   unfeasible develop  use data  used wide  variety applications  wide variety  \n",
       "0            0.000000  0.324797   0.000000              0.000000      0.000000  \n",
       "1            0.000000  0.000000   0.000000              0.000000      0.000000  \n",
       "2            0.000000  0.000000   0.000000              0.000000      0.000000  \n",
       "3            0.000000  0.000000   0.350248              0.350248      0.350248  \n",
       "4            0.000000  0.000000   0.000000              0.000000      0.000000  \n",
       "5            0.377964  0.000000   0.000000              0.000000      0.000000  \n",
       "\n",
       "[6 rows x 44 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#pd.DataFrame(matrix.toarray())\n",
    "pd.DataFrame(data, columns = vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd89aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
